[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Topik 4 Eksplorasi Data",
    "section": "",
    "text": "The good news is that these descriptive statistics give us a manageable and meaningful summary of the underlying phenomenon. That’s what this chapter is about. The bad news is that any simplification invites abuse. Descriptive statistics can be like online dating profiles: technically accurate and yet pretty darn misleading. -Charles Wheelan"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#tu-ahajaja-mama",
    "href": "index.html#tu-ahajaja-mama",
    "title": "lapbkurto web",
    "section": "Tu ahajaja mama",
    "text": "Tu ahajaja mama\nxkkmxkhe Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See more skmks"
  },
  {
    "objectID": "index.html#ajaamm",
    "href": "index.html#ajaamm",
    "title": "Topik 4 Eksplorasi Data",
    "section": "ajaamm",
    "text": "ajaamm\nshshshe Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See more he Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See more\nhe Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See more\nhe Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See more"
  },
  {
    "objectID": "index.html#ajaamm-1",
    "href": "index.html#ajaamm-1",
    "title": "Topik 4 Eksplorasi Data",
    "section": "2.1 ajaamm",
    "text": "2.1 ajaamm\nzjz"
  },
  {
    "objectID": "index.html#tu-ahajaja-mama-1",
    "href": "index.html#tu-ahajaja-mama-1",
    "title": "lapbkurto web",
    "section": "2 Tu ahajaja mama",
    "text": "2 Tu ahajaja mama\nhe Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See morehe Seine is a 777-kilometre-long (483 mi) river in northern France. Its drainage basin is in the Paris Basin (a geological relative lowland) covering most of northern France. It rises at Source-Seine, 30 kilometres (19 mi) northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris … See more xkkmxk skmks\n\n2.1 ajaamm\nzjz"
  },
  {
    "objectID": "index.html#extracting-data",
    "href": "index.html#extracting-data",
    "title": "Topik 4 Eksplorasi Data",
    "section": "4.1.1 Extracting Data",
    "text": "4.1.1 Extracting Data\nData frames are the most used data structures in R as they offer more flexibility in the way they can handle data.\n\ndata_stocks = read.csv(file =\"C:/Users/tahsi/OneDrive/Documents/Materi Data Analitik/us_stocks.csv\", header = TRUE)\nhead(data_stocks)\n\n       Date  MSFT    IBM  AAPL   MCD    PG GOOG\n1 2/01/2002 33.52 121.50 11.65 26.49 40.00   NA\n2 3/01/2002 34.62 123.66 11.79 26.79 39.62   NA\n3 4/01/2002 34.45 125.60 11.84 26.99 39.22   NA\n4 7/01/2002 34.28 124.05 11.45 27.20 38.78   NA\n5 8/01/2002 34.69 124.70 11.30 27.36 38.88   NA\n6 9/01/2002 34.36 124.49 10.82 26.88 38.60   NA\n\n\n\nnames(data_stocks)\n\n[1] \"Date\" \"MSFT\" \"IBM\"  \"AAPL\" \"MCD\"  \"PG\"   \"GOOG\"\n\n\n\ncolnames(data_stocks)\n\n[1] \"Date\" \"MSFT\" \"IBM\"  \"AAPL\" \"MCD\"  \"PG\"   \"GOOG\"\n\n\n\nmsft_prices1 = data_stocks$MSFT  #the data is returned as a vector\nhead(msft_prices1)\n\n[1] 33.52 34.62 34.45 34.28 34.69 34.36\n\n\n\nmsft_prices2 = data_stocks[[\"MSFT\"]]  #the data is returned as a vector\nhead(msft_prices2)\n\n[1] 33.52 34.62 34.45 34.28 34.69 34.36\n\n\n\n# the following returns data as a data frame\nmsft_prices3 = data_stocks[\"MSFT\"]  #can also be used to access multiple columns\nhead(msft_prices3)\n\n   MSFT\n1 33.52\n2 34.62\n3 34.45\n4 34.28\n5 34.69\n6 34.36\n\n\n\n# MSFT is in the second column and leaving the row index blank returns all the\n# rows for the particular column\n\nmsft_prices4 = data_stocks[, 2]\n\nhead(msft_prices4)\n\n[1] 33.52 34.62 34.45 34.28 34.69 34.36\n\n\n\n# all the elements in row 4\ndata_stocks[4, ]\n\n       Date  MSFT    IBM  AAPL  MCD    PG GOOG\n4 7/01/2002 34.28 124.05 11.45 27.2 38.78   NA"
  },
  {
    "objectID": "index.html#combining-data-frames",
    "href": "index.html#combining-data-frames",
    "title": "Topik 4 Eksplorasi Data",
    "section": "4.1.2 Combining Data Frames",
    "text": "4.1.2 Combining Data Frames\nIt may be required to combine two data frames during a data processing.\nThis can be done by stacking them row by row or combining them by columns using r\n\n# First create a vector having the returns for msft\nmsft_ret = 100 * diff(log(data_stocks$MSFT))\n# combine the vector with the data\n\n\n# different length\nlength(msft_ret)\n\n[1] 2783\n\n\n\nlength(data_stocks$MSFT)\n\n[1] 2784\n\n\n\n# add one more value to vector msft_ret\nmsft_ret = c(0, msft_ret)\n# check the length\nlength(msft_ret)\n\n[1] 2784\n\n\n\n# lets combine now (it should work)\ndata_stocks_r = cbind(data_stocks, MSFT_RET = msft_ret)\nhead(data_stocks_r)  #shows one more column added to the data\n\n       Date  MSFT    IBM  AAPL   MCD    PG GOOG   MSFT_RET\n1 2/01/2002 33.52 121.50 11.65 26.49 40.00   NA  0.0000000\n2 3/01/2002 34.62 123.66 11.79 26.79 39.62   NA  3.2289274\n3 4/01/2002 34.45 125.60 11.84 26.99 39.22   NA -0.4922552\n4 7/01/2002 34.28 124.05 11.45 27.20 38.78   NA -0.4946904\n5 8/01/2002 34.69 124.70 11.30 27.36 38.88   NA  1.1889367\n6 9/01/2002 34.36 124.49 10.82 26.88 38.60   NA -0.9558364\n\n\n\n# create two dataframes from data_stocks\ndata_r1 = data_stocks[1:10, ]  #first 10 rows\ndata_r2 = data_stocks[2775:2784, ]  #last 10 rows\ndata_stocks_rbind = rbind(data_r1, data_r2)\nprint(data_stocks_rbind)\n\n           Date  MSFT    IBM   AAPL   MCD    PG   GOOG\n1     2/01/2002 33.52 121.50  11.65 26.49 40.00     NA\n2     3/01/2002 34.62 123.66  11.79 26.79 39.62     NA\n3     4/01/2002 34.45 125.60  11.84 26.99 39.22     NA\n4     7/01/2002 34.28 124.05  11.45 27.20 38.78     NA\n5     8/01/2002 34.69 124.70  11.30 27.36 38.88     NA\n6     9/01/2002 34.36 124.49  10.82 26.88 38.60     NA\n7    10/01/2002 34.64 122.14  10.62 26.81 38.46     NA\n8    11/01/2002 34.30 120.31  10.52 26.34 38.60     NA\n9    14/01/2002 34.24 118.05  10.58 26.02 39.35     NA\n10   15/01/2002 34.78 118.85  10.85 26.20 39.82     NA\n2775 17/12/2012 27.10 193.62 518.83 89.91 69.93 720.78\n2776 18/12/2012 27.56 195.69 533.90 90.52 69.97 721.07\n2777 19/12/2012 27.31 195.08 526.31 89.71 69.34 720.11\n2778 20/12/2012 27.68 194.77 521.73 90.04 69.82 722.36\n2779 21/12/2012 27.45 193.42 519.33 90.18 68.72 715.63\n2780 24/12/2012 27.06 192.40 520.17 89.29 68.52 709.50\n2781 26/12/2012 26.86 191.95 513.00 88.74 68.00 708.87\n2782 27/12/2012 26.96 192.71 515.06 88.72 67.97 706.29\n2783 28/12/2012 26.55 189.83 509.59 87.58 67.15 700.01\n2784 31/12/2012 26.71 191.55 532.17 88.21 67.89 707.38"
  },
  {
    "objectID": "index.html#sub-setting-and-logical-data-selection",
    "href": "index.html#sub-setting-and-logical-data-selection",
    "title": "Topik 4 Eksplorasi Data",
    "section": "4.1.3 Sub setting and Logical Data Selection",
    "text": "4.1.3 Sub setting and Logical Data Selection\nIt may be required to combine two data frames during a data processing. This can be done by stacking them ro\n\n# select all rows with Apple prices above 100\ndata_aaplgr100 = data_stocks[data_stocks$AAPL &gt; 100, ]\nhead(data_aaplgr100)\n\n          Date  MSFT    IBM   AAPL   MCD    PG   GOOG\n1342 2/05/2007 30.61 102.22 100.39 50.02 62.37 465.78\n1343 3/05/2007 30.97 102.80 100.40 49.91 62.00 473.23\n1344 4/05/2007 30.56 102.96 100.81 49.92 62.41 471.12\n1345 7/05/2007 30.71 103.16 103.92 49.50 62.18 467.27\n1346 8/05/2007 30.75 103.29 105.06 49.32 61.75 466.81\n1347 9/05/2007 30.78 104.38 106.88 49.84 62.01 469.25\n\n\n\nmin(data_aaplgr100$AAPL)  #check if the prices are above 100\n\n[1] NA\n\n\n\n# this give NA as the minimum which indicates that data frame has NA lets\n# remove NAs from data_aaplgr100 using na.omit function\ndata_aaplgr100 = na.omit(data_aaplgr100)\n# now check the minimum again\nmin(data_aaplgr100$AAPL)\n\n[1] 100.06\n\n\n\nhead(data_stocks)  #notice NAs in GOOG\n\n       Date  MSFT    IBM  AAPL   MCD    PG GOOG\n1 2/01/2002 33.52 121.50 11.65 26.49 40.00   NA\n2 3/01/2002 34.62 123.66 11.79 26.79 39.62   NA\n3 4/01/2002 34.45 125.60 11.84 26.99 39.22   NA\n4 7/01/2002 34.28 124.05 11.45 27.20 38.78   NA\n5 8/01/2002 34.69 124.70 11.30 27.36 38.88   NA\n6 9/01/2002 34.36 124.49 10.82 26.88 38.60   NA\n\n\n\ndata_stocks_googlena = data_stocks[!is.na(data_stocks$GOOG), ]\nhead(data_stocks_googlena)  #after removing NAs\n\n          Date  MSFT   IBM  AAPL   MCD    PG   GOOG\n663 19/08/2004 27.12 84.89 15.36 26.60 54.48 100.34\n664 20/08/2004 27.20 85.25 15.40 27.07 54.85 108.31\n665 23/08/2004 27.24 84.65 15.54 26.64 54.75 109.40\n666 24/08/2004 27.24 84.71 15.98 26.87 54.95 104.87\n667 25/08/2004 27.55 85.07 16.52 26.95 55.30 106.00\n668 26/08/2004 27.44 84.69 17.33 27.10 55.70 107.91\n\n\n\n# the above can still leave NAs in other columns use na.omit to remove all the\n# blank data\ndata_stocks_naomit = na.omit(data_stocks)\n\n\ndata_msft = data_stocks_naomit[data_stocks_naomit$MSFT &lt;= 30 & data_stocks_naomit$MSFT &gt;\n    20, ]\nmin(data_msft$MSFT)  #check \n\n[1] 20.06\n\n\n\nargs(subset.data.frame)\n\nfunction (x, subset, select, drop = FALSE, ...) \nNULL\n\n\n\naaplgr100 = subset(data_stocks_naomit, AAPL &gt; 100)\nhead(aaplgr100)\n\n          Date  MSFT    IBM   AAPL   MCD    PG   GOOG\n1342 2/05/2007 30.61 102.22 100.39 50.02 62.37 465.78\n1343 3/05/2007 30.97 102.80 100.40 49.91 62.00 473.23\n1344 4/05/2007 30.56 102.96 100.81 49.92 62.41 471.12\n1345 7/05/2007 30.71 103.16 103.92 49.50 62.18 467.27\n1346 8/05/2007 30.75 103.29 105.06 49.32 61.75 466.81\n1347 9/05/2007 30.78 104.38 106.88 49.84 62.01 469.25\n\n\n\nmin(aaplgr100$AAPL)\n\n[1] 100.06"
  },
  {
    "objectID": "index.html#data-preprocessing",
    "href": "index.html#data-preprocessing",
    "title": "Topik 4 Eksplorasi Data",
    "section": "4.1 Data Preprocessing",
    "text": "4.1 Data Preprocessing\nxkkmxkhe Seine is a 777-kilometre-long (483 mi) river in northern France.\n\n4.1.1 Extracting Data\nData frames are the most used data structures in R as they offer more flexibility in the way they can handle data.\n\ndata_stocks = read.csv(file =\"data/us_stocks.csv\", header = TRUE)\nhead(data_stocks)\n\n       Date  MSFT    IBM  AAPL   MCD    PG GOOG\n1 2/01/2002 33.52 121.50 11.65 26.49 40.00   NA\n2 3/01/2002 34.62 123.66 11.79 26.79 39.62   NA\n3 4/01/2002 34.45 125.60 11.84 26.99 39.22   NA\n4 7/01/2002 34.28 124.05 11.45 27.20 38.78   NA\n5 8/01/2002 34.69 124.70 11.30 27.36 38.88   NA\n6 9/01/2002 34.36 124.49 10.82 26.88 38.60   NA\n\n\n\nnames(data_stocks)\n\n[1] \"Date\" \"MSFT\" \"IBM\"  \"AAPL\" \"MCD\"  \"PG\"   \"GOOG\"\n\n\n\ncolnames(data_stocks)\n\n[1] \"Date\" \"MSFT\" \"IBM\"  \"AAPL\" \"MCD\"  \"PG\"   \"GOOG\"\n\n\n\nmsft_prices1 = data_stocks$MSFT  #the data is returned as a vector\nhead(msft_prices1)\n\n[1] 33.52 34.62 34.45 34.28 34.69 34.36\n\n\n\nmsft_prices2 = data_stocks[[\"MSFT\"]]  #the data is returned as a vector\nhead(msft_prices2)\n\n[1] 33.52 34.62 34.45 34.28 34.69 34.36\n\n\n\n# the following returns data as a data frame\nmsft_prices3 = data_stocks[\"MSFT\"]  #can also be used to access multiple columns\nhead(msft_prices3)\n\n   MSFT\n1 33.52\n2 34.62\n3 34.45\n4 34.28\n5 34.69\n6 34.36\n\n\n\n# MSFT is in the second column and leaving the row index blank returns all the\n# rows for the particular column\n\nmsft_prices4 = data_stocks[, 2]\n\nhead(msft_prices4)\n\n[1] 33.52 34.62 34.45 34.28 34.69 34.36\n\n\n\n# all the elements in row 4\ndata_stocks[4, ]\n\n       Date  MSFT    IBM  AAPL  MCD    PG GOOG\n4 7/01/2002 34.28 124.05 11.45 27.2 38.78   NA\n\n\n\n\n4.1.2 Combining Data Frames\nIt may be required to combine two data frames during a data processing.\nThis can be done by stacking them row by row or combining them by columns using r\n\n# First create a vector having the returns for msft\nmsft_ret = 100 * diff(log(data_stocks$MSFT))\n# combine the vector with the data\n\n\n# different length\nlength(msft_ret)\n\n[1] 2783\n\n\n\nlength(data_stocks$MSFT)\n\n[1] 2784\n\n\n\n# add one more value to vector msft_ret\nmsft_ret = c(0, msft_ret)\n# check the length\nlength(msft_ret)\n\n[1] 2784\n\n\n\n# lets combine now (it should work)\ndata_stocks_r = cbind(data_stocks, MSFT_RET = msft_ret)\nhead(data_stocks_r)  #shows one more column added to the data\n\n       Date  MSFT    IBM  AAPL   MCD    PG GOOG   MSFT_RET\n1 2/01/2002 33.52 121.50 11.65 26.49 40.00   NA  0.0000000\n2 3/01/2002 34.62 123.66 11.79 26.79 39.62   NA  3.2289274\n3 4/01/2002 34.45 125.60 11.84 26.99 39.22   NA -0.4922552\n4 7/01/2002 34.28 124.05 11.45 27.20 38.78   NA -0.4946904\n5 8/01/2002 34.69 124.70 11.30 27.36 38.88   NA  1.1889367\n6 9/01/2002 34.36 124.49 10.82 26.88 38.60   NA -0.9558364\n\n\n\n# create two dataframes from data_stocks\ndata_r1 = data_stocks[1:10, ]  #first 10 rows\ndata_r2 = data_stocks[2775:2784, ]  #last 10 rows\ndata_stocks_rbind = rbind(data_r1, data_r2)\nprint(data_stocks_rbind)\n\n           Date  MSFT    IBM   AAPL   MCD    PG   GOOG\n1     2/01/2002 33.52 121.50  11.65 26.49 40.00     NA\n2     3/01/2002 34.62 123.66  11.79 26.79 39.62     NA\n3     4/01/2002 34.45 125.60  11.84 26.99 39.22     NA\n4     7/01/2002 34.28 124.05  11.45 27.20 38.78     NA\n5     8/01/2002 34.69 124.70  11.30 27.36 38.88     NA\n6     9/01/2002 34.36 124.49  10.82 26.88 38.60     NA\n7    10/01/2002 34.64 122.14  10.62 26.81 38.46     NA\n8    11/01/2002 34.30 120.31  10.52 26.34 38.60     NA\n9    14/01/2002 34.24 118.05  10.58 26.02 39.35     NA\n10   15/01/2002 34.78 118.85  10.85 26.20 39.82     NA\n2775 17/12/2012 27.10 193.62 518.83 89.91 69.93 720.78\n2776 18/12/2012 27.56 195.69 533.90 90.52 69.97 721.07\n2777 19/12/2012 27.31 195.08 526.31 89.71 69.34 720.11\n2778 20/12/2012 27.68 194.77 521.73 90.04 69.82 722.36\n2779 21/12/2012 27.45 193.42 519.33 90.18 68.72 715.63\n2780 24/12/2012 27.06 192.40 520.17 89.29 68.52 709.50\n2781 26/12/2012 26.86 191.95 513.00 88.74 68.00 708.87\n2782 27/12/2012 26.96 192.71 515.06 88.72 67.97 706.29\n2783 28/12/2012 26.55 189.83 509.59 87.58 67.15 700.01\n2784 31/12/2012 26.71 191.55 532.17 88.21 67.89 707.38\n\n\n\n\n4.1.3 Sub setting and Logical Data Selection\nIt may be required to combine two data frames during a data processing. This can be done by stacking them ro\n\n# select all rows with Apple prices above 100\ndata_aaplgr100 = data_stocks[data_stocks$AAPL &gt; 100, ]\nhead(data_aaplgr100)\n\n          Date  MSFT    IBM   AAPL   MCD    PG   GOOG\n1342 2/05/2007 30.61 102.22 100.39 50.02 62.37 465.78\n1343 3/05/2007 30.97 102.80 100.40 49.91 62.00 473.23\n1344 4/05/2007 30.56 102.96 100.81 49.92 62.41 471.12\n1345 7/05/2007 30.71 103.16 103.92 49.50 62.18 467.27\n1346 8/05/2007 30.75 103.29 105.06 49.32 61.75 466.81\n1347 9/05/2007 30.78 104.38 106.88 49.84 62.01 469.25\n\n\n\nmin(data_aaplgr100$AAPL)  #check if the prices are above 100\n\n[1] NA\n\n\n\n# this give NA as the minimum which indicates that data frame has NA lets\n# remove NAs from data_aaplgr100 using na.omit function\ndata_aaplgr100 = na.omit(data_aaplgr100)\n# now check the minimum again\nmin(data_aaplgr100$AAPL)\n\n[1] 100.06\n\n\n\nhead(data_stocks)  #notice NAs in GOOG\n\n       Date  MSFT    IBM  AAPL   MCD    PG GOOG\n1 2/01/2002 33.52 121.50 11.65 26.49 40.00   NA\n2 3/01/2002 34.62 123.66 11.79 26.79 39.62   NA\n3 4/01/2002 34.45 125.60 11.84 26.99 39.22   NA\n4 7/01/2002 34.28 124.05 11.45 27.20 38.78   NA\n5 8/01/2002 34.69 124.70 11.30 27.36 38.88   NA\n6 9/01/2002 34.36 124.49 10.82 26.88 38.60   NA\n\n\n\ndata_stocks_googlena = data_stocks[!is.na(data_stocks$GOOG), ]\nhead(data_stocks_googlena)  #after removing NAs\n\n          Date  MSFT   IBM  AAPL   MCD    PG   GOOG\n663 19/08/2004 27.12 84.89 15.36 26.60 54.48 100.34\n664 20/08/2004 27.20 85.25 15.40 27.07 54.85 108.31\n665 23/08/2004 27.24 84.65 15.54 26.64 54.75 109.40\n666 24/08/2004 27.24 84.71 15.98 26.87 54.95 104.87\n667 25/08/2004 27.55 85.07 16.52 26.95 55.30 106.00\n668 26/08/2004 27.44 84.69 17.33 27.10 55.70 107.91\n\n\n\n# the above can still leave NAs in other columns use na.omit to remove all the\n# blank data\ndata_stocks_naomit = na.omit(data_stocks)\n\n\ndata_msft = data_stocks_naomit[data_stocks_naomit$MSFT &lt;= 30 & data_stocks_naomit$MSFT &gt;\n    20, ]\nmin(data_msft$MSFT)  #check \n\n[1] 20.06\n\n\n\nargs(subset.data.frame)\n\nfunction (x, subset, select, drop = FALSE, ...) \nNULL\n\n\n\naaplgr100 = subset(data_stocks_naomit, AAPL &gt; 100)\nhead(aaplgr100)\n\n          Date  MSFT    IBM   AAPL   MCD    PG   GOOG\n1342 2/05/2007 30.61 102.22 100.39 50.02 62.37 465.78\n1343 3/05/2007 30.97 102.80 100.40 49.91 62.00 473.23\n1344 4/05/2007 30.56 102.96 100.81 49.92 62.41 471.12\n1345 7/05/2007 30.71 103.16 103.92 49.50 62.18 467.27\n1346 8/05/2007 30.75 103.29 105.06 49.32 61.75 466.81\n1347 9/05/2007 30.78 104.38 106.88 49.84 62.01 469.25\n\n\n\nmin(aaplgr100$AAPL)\n\n[1] 100.06"
  },
  {
    "objectID": "index.html#data-transformation-from-wide-to-long-or-vice-versa",
    "href": "index.html#data-transformation-from-wide-to-long-or-vice-versa",
    "title": "Topik 4 Eksplorasi Data",
    "section": "4.2 Data Transformation from Wide to Long (or vice versa)",
    "text": "4.2 Data Transformation from Wide to Long (or vice versa)\nIt may be\n\nlibrary(tidyr)\n\nFinData_long = pivot_longer(data = data_stocks, cols = -Date, names_to = \"Stock\",\n    values_to = \"Price\")\nhead(FinData_long)\n\n# A tibble: 6 × 3\n  Date      Stock Price\n  &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;\n1 2/01/2002 MSFT   33.5\n2 2/01/2002 IBM   122. \n3 2/01/2002 AAPL   11.6\n4 2/01/2002 MCD    26.5\n5 2/01/2002 PG     40  \n6 2/01/2002 GOOG   NA  \n\n\n\nFinData_wide = pivot_wider(FinData_long, names_from = Stock, values_from = Price)\nhead(FinData_wide)\n\n# A tibble: 6 × 7\n  Date       MSFT   IBM  AAPL   MCD    PG  GOOG\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2/01/2002  33.5  122.  11.6  26.5  40      NA\n2 3/01/2002  34.6  124.  11.8  26.8  39.6    NA\n3 4/01/2002  34.4  126.  11.8  27.0  39.2    NA\n4 7/01/2002  34.3  124.  11.4  27.2  38.8    NA\n5 8/01/2002  34.7  125.  11.3  27.4  38.9    NA\n6 9/01/2002  34.4  124.  10.8  26.9  38.6    NA"
  },
  {
    "objectID": "index.html#summary-statistics",
    "href": "index.html#summary-statistics",
    "title": "Topik 4 Eksplorasi Data",
    "section": "4.3 Summary Statistics",
    "text": "4.3 Summary Statistics\n\n# change the working directory to the folder containing data_fin.csv or provide\n# the full path with the filename\ndata_stocks = read.csv(\"data/data_fin.csv\")  #import data\nhead(data_stocks)\n\n        Date     DJI   AXP   MMM   ATT    BA   CAT CISCO    DD   XOM    GE\n1  3/01/2000 11357.5 45.82 47.19 47.19 40.12 24.31 54.05 65.00 39.09 49.95\n2  4/01/2000 10997.9 44.09 45.31 44.25 40.12 24.00 51.00 65.00 38.41 48.06\n3  5/01/2000 11122.7 42.96 46.62 44.94 42.62 24.56 51.19 67.75 40.50 47.70\n4  6/01/2000 11253.3 43.78 50.62 43.75 43.06 25.81 50.00 71.50 42.59 48.51\n5  7/01/2000 11522.6 44.42 51.47 44.12 44.12 26.66 52.94 71.62 42.31 50.28\n6 10/01/2000 11572.2 45.04 51.12 44.75 43.69 25.78 54.91 70.00 41.88 50.37\n     GS    HD    IBM  INTC   JNJ   JPM   MRK   MCD  MSFT   NKE\n1 88.31 65.50 115.56 43.47 46.09 48.69 64.04 39.62 58.34 12.03\n2 82.38 61.50 112.06 41.47 44.41 47.27 61.61 38.81 56.31 11.38\n3 78.88 61.44 116.00 41.81 44.88 46.98 64.22 39.44 56.91 12.03\n4 82.25 60.00 114.62 39.38 46.28 47.65 64.75 38.88 55.00 11.97\n5 82.56 62.81 113.31 41.00 47.88 48.52 70.97 39.75 55.72 11.97\n6 84.38 63.19 118.44 42.88 47.03 47.69 68.89 40.06 56.12 12.17\n\n\n\nDJI = data_stocks$DJI\nDJI = na.omit(DJI)  #remove NAs as it will affect the calculations\n# Arithmetic mean\nmean(DJI)\n\n[1] 11098.12\n\n\n\n# Geometric mean\nexp(mean(log(DJI)))\n\n[1] 10953.39\n\n\n\n# median\nmedian(DJI)\n\n[1] 10748.8\n\n# variance & standard deviation\nvar(DJI)\n\n[1] 3280347\n\nsd(DJI)\n\n[1] 1811.173\n\n# interquantile range and few quantiles\nIQR(DJI)\n\n[1] 2276.25\n\nquantile(DJI)\n\n      0%      25%      50%      75%     100% \n 6547.10 10063.25 10748.80 12339.50 16576.66 \n\n# skewness and kurtosis skewness and kurtosis functions are not available in R\n# core library but in library e1071 (there are other packages which have\n# functions for skewness and kurtosis try ??kurtosis or search for the function\n# on RSearch.\nlibrary(e1071)\nskewness(DJI)\n\n[1] 0.4777828\n\nkurtosis(DJI)\n\n[1] 0.08404185\n\n\n\n# summary of one column/variable in a dataframe\nsummary(DJI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   6547   10063   10749   11098   12340   16577 \n\n# summary of whole dataset excluding the time column\nsummary(data_stocks[, c(2:21)])\n\n      DJI             AXP             MMM              ATT       \n Min.   : 6547   Min.   :10.26   Min.   : 39.50   Min.   :19.34  \n 1st Qu.:10063   1st Qu.:38.31   1st Qu.: 62.55   1st Qu.:25.54  \n Median :10749   Median :47.49   Median : 77.67   Median :29.65  \n Mean   :11098   Mean   :46.77   Mean   : 75.78   Mean   :31.77  \n 3rd Qu.:12340   3rd Qu.:54.44   3rd Qu.: 85.55   3rd Qu.:37.22  \n Max.   :16577   Max.   :90.73   Max.   :140.25   Max.   :58.50  \n NA's   :27      NA's   :12      NA's   :12       NA's   :12     \n       BA              CAT             CISCO             DD       \n Min.   : 25.06   Min.   : 14.91   Min.   : 8.60   Min.   :16.14  \n 1st Qu.: 44.00   1st Qu.: 28.64   1st Qu.:17.68   1st Qu.:41.13  \n Median : 63.56   Median : 57.10   Median :20.43   Median :44.53  \n Mean   : 62.95   Mean   : 56.01   Mean   :23.41   Mean   :44.37  \n 3rd Qu.: 74.90   3rd Qu.: 79.36   3rd Qu.:24.17   3rd Qu.:48.92  \n Max.   :138.36   Max.   :116.20   Max.   :80.06   Max.   :71.62  \n NA's   :12       NA's   :12       NA's   :13      NA's   :12     \n      XOM               GE              GS              HD       \n Min.   : 30.27   Min.   : 6.66   Min.   : 52.0   Min.   :18.00  \n 1st Qu.: 42.46   1st Qu.:20.00   1st Qu.: 92.2   1st Qu.:31.00  \n Median : 64.77   Median :30.33   Median :116.2   Median :37.37  \n Mean   : 63.20   Mean   :29.56   Mean   :126.9   Mean   :40.20  \n 3rd Qu.: 81.62   3rd Qu.:36.03   3rd Qu.:159.5   3rd Qu.:46.23  \n Max.   :101.51   Max.   :59.94   Max.   :247.9   Max.   :82.34  \n NA's   :12       NA's   :12      NA's   :12      NA's   :12     \n      IBM              INTC            JNJ             JPM       \n Min.   : 55.07   Min.   :12.08   Min.   :33.69   Min.   :15.45  \n 1st Qu.: 87.82   1st Qu.:20.17   1st Qu.:55.27   1st Qu.:35.66  \n Median :106.48   Median :22.76   Median :61.30   Median :40.20  \n Mean   :118.83   Mean   :25.21   Mean   :61.07   Mean   :40.36  \n 3rd Qu.:130.00   3rd Qu.:26.77   3rd Qu.:65.20   3rd Qu.:45.71  \n Max.   :215.80   Max.   :74.88   Max.   :95.63   Max.   :65.70  \n NA's   :12       NA's   :13      NA's   :12      NA's   :12     \n      MRK             MCD              MSFT            NKE       \n Min.   :20.99   Min.   : 12.38   Min.   :15.15   Min.   : 6.64  \n 1st Qu.:34.53   1st Qu.: 29.19   1st Qu.:25.67   1st Qu.:14.56  \n Median :43.63   Median : 43.78   Median :27.59   Median :23.25  \n Mean   :44.65   Mean   : 51.07   Mean   :28.38   Mean   :28.01  \n 3rd Qu.:51.55   3rd Qu.: 70.36   3rd Qu.:30.19   3rd Qu.:36.90  \n Max.   :89.85   Max.   :103.59   Max.   :58.34   Max.   :79.86  \n NA's   :13      NA's   :12       NA's   :13      NA's   :12     \n\n\n\n4.3.1 Example-Descriptive Statistics of Stock Returns\nIn this example we will use R to calcu\n\ndata_cs1 = read.csv(\"C:/Users/tahsi/OneDrive/Documents/Materi Data Analitik/data_fin.csv\")\nhead(data_cs1)  #check the imported data\n\n        Date     DJI   AXP   MMM   ATT    BA   CAT CISCO    DD   XOM    GE\n1  3/01/2000 11357.5 45.82 47.19 47.19 40.12 24.31 54.05 65.00 39.09 49.95\n2  4/01/2000 10997.9 44.09 45.31 44.25 40.12 24.00 51.00 65.00 38.41 48.06\n3  5/01/2000 11122.7 42.96 46.62 44.94 42.62 24.56 51.19 67.75 40.50 47.70\n4  6/01/2000 11253.3 43.78 50.62 43.75 43.06 25.81 50.00 71.50 42.59 48.51\n5  7/01/2000 11522.6 44.42 51.47 44.12 44.12 26.66 52.94 71.62 42.31 50.28\n6 10/01/2000 11572.2 45.04 51.12 44.75 43.69 25.78 54.91 70.00 41.88 50.37\n     GS    HD    IBM  INTC   JNJ   JPM   MRK   MCD  MSFT   NKE\n1 88.31 65.50 115.56 43.47 46.09 48.69 64.04 39.62 58.34 12.03\n2 82.38 61.50 112.06 41.47 44.41 47.27 61.61 38.81 56.31 11.38\n3 78.88 61.44 116.00 41.81 44.88 46.98 64.22 39.44 56.91 12.03\n4 82.25 60.00 114.62 39.38 46.28 47.65 64.75 38.88 55.00 11.97\n5 82.56 62.81 113.31 41.00 47.88 48.52 70.97 39.75 55.72 11.97\n6 84.38 63.19 118.44 42.88 47.03 47.69 68.89 40.06 56.12 12.17\n\n\n\n# selecting first 10 price series including the data column\ndata_cs1.1 = data_cs1[, c(1:11)]\n# data cleaning-remove NAs\ndata_cs1.1 = na.omit(data_cs1.1)\ncolnames(data_cs1.1)  # see the columns present in the data\n\n [1] \"Date\"  \"DJI\"   \"AXP\"   \"MMM\"   \"ATT\"   \"BA\"    \"CAT\"   \"CISCO\" \"DD\"   \n[10] \"XOM\"   \"GE\"   \n\nsummary(data_cs1.1)  #notice the Date variable\n\n     Date                DJI             AXP             MMM        \n Length:3523        Min.   : 6547   Min.   :10.26   Min.   : 39.50  \n Class :character   1st Qu.:10063   1st Qu.:38.38   1st Qu.: 62.55  \n Mode  :character   Median :10749   Median :47.60   Median : 77.67  \n                    Mean   :11098   Mean   :46.83   Mean   : 75.80  \n                    3rd Qu.:12340   3rd Qu.:54.50   3rd Qu.: 85.61  \n                    Max.   :16577   Max.   :90.73   Max.   :140.25  \n      ATT              BA              CAT             CISCO      \n Min.   :19.34   Min.   : 25.06   Min.   : 14.91   Min.   : 8.60  \n 1st Qu.:25.54   1st Qu.: 44.02   1st Qu.: 28.48   1st Qu.:17.68  \n Median :29.76   Median : 63.61   Median : 57.11   Median :20.39  \n Mean   :31.79   Mean   : 62.99   Mean   : 56.03   Mean   :23.42  \n 3rd Qu.:37.23   3rd Qu.: 74.95   3rd Qu.: 79.50   3rd Qu.:24.18  \n Max.   :58.50   Max.   :138.36   Max.   :116.20   Max.   :80.06  \n       DD             XOM               GE       \n Min.   :16.14   Min.   : 30.27   Min.   : 6.66  \n 1st Qu.:41.17   1st Qu.: 42.41   1st Qu.:20.04  \n Median :44.58   Median : 64.70   Median :30.37  \n Mean   :44.43   Mean   : 63.18   Mean   :29.63  \n 3rd Qu.:48.93   3rd Qu.: 81.70   3rd Qu.:36.05  \n Max.   :71.62   Max.   :101.51   Max.   :59.94  \n\n# check class of dates which will be factor ( treated as factor by default)\\t\nclass(data_cs1.1$Date)\n\n[1] \"character\"\n\n# convert dates to class Date\ndata_cs1.1$Date = as.Date(data_cs1.1$Date, format = \"%d/%m/%Y\")\nclass(data_cs1.1$Date)\n\n[1] \"Date\"\n\nsummary(data_cs1.1)  #notice the Date variable\n\n      Date                 DJI             AXP             MMM        \n Min.   :2000-01-03   Min.   : 6547   Min.   :10.26   Min.   : 39.50  \n 1st Qu.:2003-07-08   1st Qu.:10063   1st Qu.:38.38   1st Qu.: 62.55  \n Median :2007-01-05   Median :10749   Median :47.60   Median : 77.67  \n Mean   :2007-01-03   Mean   :11098   Mean   :46.83   Mean   : 75.80  \n 3rd Qu.:2010-07-06   3rd Qu.:12340   3rd Qu.:54.50   3rd Qu.: 85.61  \n Max.   :2014-01-03   Max.   :16577   Max.   :90.73   Max.   :140.25  \n      ATT              BA              CAT             CISCO      \n Min.   :19.34   Min.   : 25.06   Min.   : 14.91   Min.   : 8.60  \n 1st Qu.:25.54   1st Qu.: 44.02   1st Qu.: 28.48   1st Qu.:17.68  \n Median :29.76   Median : 63.61   Median : 57.11   Median :20.39  \n Mean   :31.79   Mean   : 62.99   Mean   : 56.03   Mean   :23.42  \n 3rd Qu.:37.23   3rd Qu.: 74.95   3rd Qu.: 79.50   3rd Qu.:24.18  \n Max.   :58.50   Max.   :138.36   Max.   :116.20   Max.   :80.06  \n       DD             XOM               GE       \n Min.   :16.14   Min.   : 30.27   Min.   : 6.66  \n 1st Qu.:41.17   1st Qu.: 42.41   1st Qu.:20.04  \n Median :44.58   Median : 64.70   Median :30.37  \n Mean   :44.43   Mean   : 63.18   Mean   :29.63  \n 3rd Qu.:48.93   3rd Qu.: 81.70   3rd Qu.:36.05  \n Max.   :71.62   Max.   :101.51   Max.   :59.94  \n\n\n\nd2 = as.data.frame(sapply(data_cs1.1[2:11], function(x) diff(log(x)) * 100))  #note it will be one less\n# create a different dataframe with returns\ndata_stocks_ret = as.data.frame(cbind(Date = data_cs1.1$Date[2:length(data_cs1.1$Date)],\n    d2), stringsAsFactors = FALSE, row.names = NULL)\n# visual inspection\nhead(data_stocks_ret)\n\n        Date        DJI        AXP        MMM        ATT         BA       CAT\n1 2000-01-04 -3.2173973 -3.8487678 -4.0654247 -6.4326634  0.0000000 -1.283396\n2 2000-01-05  1.1283720 -2.5963549  2.8501875  1.5472895  6.0448664  2.306527\n3 2000-01-06  1.1673354  1.8907642  8.2317122 -2.6836654  1.0270865  4.964291\n4 2000-01-07  2.3648905  1.4512726  1.6652359  0.8421582  2.4318702  3.240230\n5 2000-01-10  0.4295346  1.3861165 -0.6823304  1.4178250 -0.9793951 -3.356532\n6 2000-01-11 -0.5293883  0.9061837 -1.7165263 -1.4178250 -1.8713726 -1.563754\n       CISCO         DD        XOM         GE\n1 -5.8083911  0.0000000 -1.7548837 -3.8572275\n2  0.3718568  4.1437190  5.2984132 -0.7518832\n3 -2.3521195  5.3872990  5.0317510  1.6838564\n4  5.7136191  0.1676915 -0.6596019  3.5837421\n5  3.6536284 -2.2879123 -1.0215079  0.1788376\n6 -3.0697677 -1.8018506  1.1868167  0.2379537\n\n\n\n4.3.1.1 Using the Describe function\nThe package psych comes with a function called which generated the descriptive statistics for all the data vectors (columns) in a data frame, mwe will use R to calcu\n\nlibrary(psych)  #load the required package\n\nWarning: package 'psych' was built under R version 4.3.1\n\nargs(describe)  #arguments for describe function\n\nfunction (x, na.rm = TRUE, interp = FALSE, skew = TRUE, ranges = TRUE, \n    trim = 0.1, type = 3, check = TRUE, fast = NULL, quant = NULL, \n    IQR = FALSE, omit = FALSE, data = NULL) \nNULL\n\n# use describe to calculate descriptive stats for data_cs1.1r\ndesc1 = describe(data_stocks_ret[, 2:11])  #note we dont pass the date column\n# check the output\nhead(desc1)\n\n    vars    n  mean   sd median trimmed  mad    min   max range  skew kurtosis\nDJI    1 3522  0.01 1.23   0.04    0.03 0.82  -8.20 10.51 18.71 -0.06     7.71\nAXP    2 3522  0.02 2.89   0.02    0.03 1.55 -19.35 18.77 38.12 -0.01     9.14\nMMM    3 3522  0.03 1.55   0.03    0.03 1.10  -9.38 10.39 19.78  0.06     4.87\nATT    4 3522 -0.01 1.80   0.03    0.01 1.22 -13.54 15.08 28.62  0.02     6.26\nBA     5 3522  0.03 2.01   0.05    0.06 1.57 -19.39 14.38 33.77 -0.26     5.39\nCAT    6 3522  0.04 2.14   0.04    0.05 1.65 -15.69 13.73 29.42 -0.08     4.08\n      se\nDJI 0.02\nAXP 0.05\nMMM 0.03\nATT 0.03\nBA  0.03\nCAT 0.04\n\n# the above output is in long format, we can transpose it get column format\ndesc1.t = t(desc1)\nhead(desc1.t)\n\n                 DJI          AXP          MMM           ATT           BA\nvars    1.000000e+00 2.000000e+00 3.000000e+00  4.000000e+00 5.000000e+00\nn       3.522000e+03 3.522000e+03 3.522000e+03  3.522000e+03 3.522000e+03\nmean    1.055257e-02 1.908563e-02 3.056011e-02 -8.647491e-03 3.499777e-02\nsd      1.226702e+00 2.892586e+00 1.551706e+00  1.799180e+00 2.013123e+00\nmedian  4.442671e-02 1.723604e-02 3.233787e-02  3.018428e-02 5.279680e-02\ntrimmed 2.597511e-02 3.152635e-02 3.241946e-02  9.134423e-03 5.567097e-02\n                 CAT         CISCO            DD          XOM            GE\nvars    6.000000e+00  7.000000e+00  8.000000e+00 9.000000e+00  1.000000e+01\nn       3.522000e+03  3.522000e+03  3.522000e+03 3.522000e+03  3.522000e+03\nmean    3.710732e-02 -2.554732e-02 -5.379787e-04 2.653014e-02 -1.696661e-02\nsd      2.143040e+00  2.744068e+00  1.881993e+00 1.629181e+00  2.057353e+00\nmedian  4.291300e-02  3.800312e-02  0.000000e+00 5.437650e-02  0.000000e+00\ntrimmed 4.678016e-02 -1.339579e-04  1.469270e-03 4.883990e-02  9.841473e-05\n\nrequire(pastecs)  # note library and require can both be used to include a package\n\nLoading required package: pastecs\n\n\nWarning: package 'pastecs' was built under R version 4.3.1\n\n\n\nAttaching package: 'pastecs'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n# detach the package pastecs its useful to avoid any conflicts (e.g psych and\n# Hmisc have 'describe' function with two different behaviours\ndetach(\"package:psych\", unload = TRUE)\n# use stat.desc in with default arguments\ndesc2 = stat.desc(data_stocks_ret[, 2:11], norm = TRUE)\ndesc2  #note skewness/kurtosis\n\n                       DJI           AXP           MMM           ATT\nnbr.val       3.522000e+03  3.522000e+03  3.522000e+03  3.522000e+03\nnbr.null      2.000000e+00  2.400000e+01  3.000000e+01  5.000000e+01\nnbr.na        0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\nmin          -8.200737e+00 -1.935233e+01 -9.383688e+00 -1.353821e+01\nmax           1.050812e+01  1.877116e+01  1.039309e+01  1.508318e+01\nrange         1.870886e+01  3.812349e+01  1.977678e+01  2.862139e+01\nsum           3.716616e+01  6.721959e+01  1.076327e+02 -3.045646e+01\nmedian        4.442671e-02  1.723604e-02  3.233787e-02  3.018428e-02\nmean          1.055257e-02  1.908563e-02  3.056011e-02 -8.647491e-03\nSE.mean       2.067018e-02  4.874068e-02  2.614656e-02  3.031656e-02\nCI.mean.0.95  4.052675e-02  9.556282e-02  5.126395e-02  5.943979e-02\nvar           1.504798e+00  8.367052e+00  2.407790e+00  3.237048e+00\nstd.dev       1.226702e+00  2.892586e+00  1.551706e+00  1.799180e+00\ncoef.var      1.162467e+02  1.515583e+02  5.077551e+01 -2.080580e+02\nskewness     -5.829983e-02 -6.689750e-03  5.927112e-02  1.620418e-02\nskew.2SE     -7.065472e-01 -8.107441e-02  7.183185e-01  1.963817e-01\nkurtosis      7.714304e+00  9.141053e+00  4.865294e+00  6.257155e+00\nkurt.2SE      4.675883e+01  5.540681e+01  2.949008e+01  3.792659e+01\nnormtest.W    9.187712e-01  8.496717e-01  9.384591e-01  9.298653e-01\nnormtest.p    5.671566e-40  1.020339e-49  6.131053e-36  8.237017e-38\n                        BA           CAT         CISCO            DD\nnbr.val       3.522000e+03  3.522000e+03  3.522000e+03  3.522000e+03\nnbr.null      1.500000e+01  2.400000e+01  5.000000e+01  2.900000e+01\nnbr.na        0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\nmin          -1.938931e+01 -1.568589e+01 -1.768649e+01 -1.202802e+01\nmax           1.437774e+01  1.373497e+01  2.182386e+01  1.085590e+01\nrange         3.376704e+01  2.942086e+01  3.951034e+01  2.288392e+01\nsum           1.232621e+02  1.306920e+02 -8.997766e+01 -1.894761e+00\nmedian        5.279680e-02  4.291300e-02  3.800312e-02  0.000000e+00\nmean          3.499777e-02  3.710732e-02 -2.554732e-02 -5.379787e-04\nSE.mean       3.392155e-02  3.611067e-02  4.623812e-02  3.171197e-02\nCI.mean.0.95  6.650788e-02  7.079996e-02  9.065621e-02  6.217570e-02\nvar           4.052665e+00  4.592620e+00  7.529907e+00  3.541897e+00\nstd.dev       2.013123e+00  2.143040e+00  2.744068e+00  1.881993e+00\ncoef.var      5.752148e+01  5.775248e+01 -1.074112e+02 -3.498266e+03\nskewness     -2.605203e-01 -8.369997e-02  1.547891e-01 -1.523353e-01\nskew.2SE     -3.157298e+00 -1.014377e+00  1.875920e+00 -1.846181e+00\nkurtosis      5.392404e+00  4.077013e+00  7.329406e+00  5.061290e+00\nkurt.2SE      3.268507e+01  2.471206e+01  4.442585e+01  3.067808e+01\nnormtest.W    9.550329e-01  9.583075e-01  9.104004e-01  9.381393e-01\nnormtest.p    1.196739e-31  1.172506e-30  1.882675e-41  5.179385e-36\n                       XOM            GE\nnbr.val       3.522000e+03  3.522000e+03\nnbr.null      2.900000e+01  6.300000e+01\nnbr.na        0.000000e+00  0.000000e+00\nmin          -1.502710e+01 -1.368410e+01\nmax           1.586307e+01  1.798444e+01\nrange         3.089017e+01  3.166854e+01\nsum           9.343915e+01 -5.975640e+01\nmedian        5.437650e-02  0.000000e+00\nmean          2.653014e-02 -1.696661e-02\nSE.mean       2.745205e-02  3.466683e-02\nCI.mean.0.95  5.382353e-02  6.796911e-02\nvar           2.654232e+00  4.232702e+00\nstd.dev       1.629181e+00  2.057353e+00\ncoef.var      6.140870e+01 -1.212589e+02\nskewness      4.651513e-02  1.102593e-02\nskew.2SE      5.637262e-01  1.336254e-01\nkurtosis      1.043194e+01  7.781017e+00\nkurt.2SE      6.323129e+01  4.716320e+01\nnormtest.W    9.160764e-01  9.046828e-01\nnormtest.p    1.839459e-40  2.126284e-42"
  }
]